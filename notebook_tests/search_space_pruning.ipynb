{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "#https://zilliz.com/learn/learn-hnswlib-graph-based-library-for-fast-anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HNSW index\n",
    "dim = 128  # Dimensionality of embeddings\n",
    "num_elements = 1000  # Number of elements to index\n",
    "\n",
    "# Declare index\n",
    "p = hnswlib.Index(space='cosine', dim=dim)\n",
    "# Initialize index\n",
    "p.init_index(max_elements=num_elements, ef_construction=200, M=16)\n",
    "\n",
    "# Generate some random embeddings to simulate table embeddings\n",
    "np.random.seed(42)\n",
    "data_embeddings = np.random.rand(num_elements, dim).astype(np.float32)\n",
    "\n",
    "# Add embeddings to the index\n",
    "ids = np.arange(num_elements)\n",
    "p.add_items(data_embeddings, ids)\n",
    "\n",
    "# Controlling the recall by setting ef\n",
    "p.set_ef(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial query results (IDs): [[701 838  39  35 227 608 386 829  46 143]]\n",
      "Initial distances: [[0.18405348 0.19224834 0.19564259 0.1965757  0.19673234 0.19941866\n",
      "  0.20007324 0.20098096 0.2027269  0.20346034]]\n"
     ]
    }
   ],
   "source": [
    "# Simulate a query embedding\n",
    "query_embedding = np.random.rand(dim).astype(np.float32)\n",
    "\n",
    "# Perform the initial search\n",
    "initial_k = 10  # Number of closest elements to find\n",
    "initial_labels, distances = p.knn_query(query_embedding, k=initial_k)\n",
    "\n",
    "print(\"Initial query results (IDs):\", initial_labels)\n",
    "print(\"Initial distances:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow-up query results (IDs): [[701 838  39  35 227]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the embeddings corresponding to the initial search results\n",
    "# Flatten the initial_labels array and extract unique IDs to avoid duplicates in case of multiple queries\n",
    "unique_initial_ids = np.unique(initial_labels.flatten())\n",
    "\n",
    "# Create a refined subset of embeddings based on the initial query results\n",
    "refined_embeddings = data_embeddings[unique_initial_ids]\n",
    "\n",
    "# Initialize a new HNSW index for the refined subset\n",
    "p_refined = hnswlib.Index(space='cosine', dim=dim)\n",
    "num_elements_refined = len(unique_initial_ids)  # Number of elements in the refined subset\n",
    "\n",
    "# Initialize the refined index with parameters suited for the smaller dataset\n",
    "p_refined.init_index(max_elements=num_elements_refined, ef_construction=100, M=16)\n",
    "\n",
    "# Add the refined subset of embeddings to the new index\n",
    "# Use the unique_initial_ids as the ids for the refined embeddings to maintain a reference to the original dataset\n",
    "p_refined.add_items(refined_embeddings, unique_initial_ids)\n",
    "\n",
    "# Adjust ef for the refined search\n",
    "p_refined.set_ef(10)\n",
    "\n",
    "# Perform a follow-up query using the refined index\n",
    "labels_refined, distances_refined = p_refined.knn_query(query_embedding, k=5)\n",
    "\n",
    "print(\"Follow-up query results (IDs):\", labels_refined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
